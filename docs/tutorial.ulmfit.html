---

title: Transfer learning in text

keywords: fastai
sidebar: home_sidebar

summary: "How to fine-tune a language model and train a classifier"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/38_tutorial.ulmfit.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai2.text.all</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev.showdoc</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># all_slow</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Finetune-a-pretrained-Language-Model">Finetune a pretrained Language Model<a class="anchor-link" href="#Finetune-a-pretrained-Language-Model">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First we get our data and tokenize it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">IMDB_SAMPLE</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;texts.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we put it in a <a href="/data.core#Datasets"><code>Datasets</code></a>. For a language model, we don't have targets, so there is only one transform to numericalize the texts.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">splits</span> <span class="o">=</span> <span class="n">ColSplitter</span><span class="p">()(</span><span class="n">df</span><span class="p">)</span>
<span class="n">tfms</span> <span class="o">=</span> <span class="p">[</span><span class="n">attrgetter</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">),</span> <span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">),</span> <span class="n">Numericalize</span><span class="p">()]</span>
<span class="n">dsets</span> <span class="o">=</span> <span class="n">Datasets</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="n">tfms</span><span class="p">],</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">dl_type</span><span class="o">=</span><span class="n">LMDataLoader</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we use that <a href="/data.core#Datasets"><code>Datasets</code></a> to create a <a href="/data.core#DataLoaders"><code>DataLoaders</code></a>. Here the class of <a href="/data.core#TfmdDL"><code>TfmdDL</code></a> we need to use is <a href="/text.data#LMDataLoader"><code>LMDataLoader</code></a> which will concatenate all the texts in a source (with a shuffle at each epoch for the training set), split it in <code>bs</code> chunks then read continuously through it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="mi">72</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Or more simply with a factory method:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TextDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">text_col</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">is_lm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">valid_col</span><span class="o">=</span><span class="s1">&#39;is_valid&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>text_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj this film is awful . xxmaj the xxup cgi is the very cheap gray blob xxup cgi . xxmaj the crocodile looks like a large gray xxunk . xxmaj the worst is that no effort at all is given to making it walk or look like it is alive . xxmaj it is mostly a photo - xxunk xxup cgi that is placed into scenes and you almost expect to</td>
      <td>xxmaj this film is awful . xxmaj the xxup cgi is the very cheap gray blob xxup cgi . xxmaj the crocodile looks like a large gray xxunk . xxmaj the worst is that no effort at all is given to making it walk or look like it is alive . xxmaj it is mostly a photo - xxunk xxup cgi that is placed into scenes and you almost expect to see</td>
    </tr>
    <tr>
      <th>1</th>
      <td>" red " ( cheech is another role ) is in town and wants to hang with him . xxmaj xxunk that he could kill two xxunk with one stone , xxmaj cheech xxunk xxmaj chong off and xxmaj red . xxmaj what kind of adventures will xxmaj chong and xxmaj red get into ? xxmaj will xxmaj cheech get his freak on ? xxmaj how long will xxmaj chong go without</td>
      <td>red " ( cheech is another role ) is in town and wants to hang with him . xxmaj xxunk that he could kill two xxunk with one stone , xxmaj cheech xxunk xxmaj chong off and xxmaj red . xxmaj what kind of adventures will xxmaj chong and xxmaj red get into ? xxmaj will xxmaj cheech get his freak on ? xxmaj how long will xxmaj chong go without some</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we have a convenience method to directly grab a <a href="/learner#Learner"><code>Learner</code></a> from it, using the <a href="/text.models.awdlstm#AWD_LSTM"><code>AWD_LSTM</code></a> architecture.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">language_model_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">,</span> <span class="n">Perplexity</span><span class="p">()],</span> <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.573556</td>
      <td>4.047952</td>
      <td>0.275492</td>
      <td>57.280037</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>perplexity</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>4.307861</td>
      <td>4.162732</td>
      <td>0.255753</td>
      <td>64.246811</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>4.138291</td>
      <td>4.076338</td>
      <td>0.271093</td>
      <td>58.929264</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>3.813226</td>
      <td>4.041671</td>
      <td>0.274977</td>
      <td>56.921394</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>3</td>
      <td>3.449531</td>
      <td>4.080863</td>
      <td>0.273898</td>
      <td>59.196533</td>
      <td>00:08</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Once we have fine-tuned the pretrained language model to this corpus, we save the encoder since we will use it for the classifier.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>input</th>
      <th>target</th>
      <th>pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj with a title " borrowed " from xxmaj xxunk xxmaj xxunk and liberal xxunk of xxmaj kubrick , xxmaj xxunk and xxmaj xxunk it is painfully obvious that xxmaj thomas xxmaj clay considers himself a cut above the usual sort of rubbish our xxmaj british cinema xxunk out . " robert xxmaj xxunk " ( for short ) sets itself up as a realistic study of youthful alienation and at</td>
      <td>xxmaj with a title " borrowed " from xxmaj xxunk xxmaj xxunk and liberal xxunk of xxmaj kubrick , xxmaj xxunk and xxmaj xxunk it is painfully obvious that xxmaj thomas xxmaj clay considers himself a cut above the usual sort of rubbish our xxmaj british cinema xxunk out . " robert xxmaj xxunk " ( for short ) sets itself up as a realistic study of youthful alienation and at the</td>
      <td>xxmaj this xxmaj very that xxunk from from " xxunk xxmaj xxunk 's " xxmaj , " xxunk 's i xxunk xxmaj xxmaj xxunk are are a xxunk that the xxunk xxmaj xxunk and this a " - the xxunk xxunk of xxunk . xxmaj xxunk xxunk has . of xxmaj xxunk xxmaj xxunk " is aka " ) is out up as a xxunk and on the xxunk and xxunk the</td>
    </tr>
    <tr>
      <th>1</th>
      <td>of xxmaj oz " ( that film 's makeup results though , worked xxunk , as this one 's does not ) . xxmaj and a comparison with xxmaj baryshnikov 's nutcracker in * his * production shows how wonderfully creative xxmaj baryshnikov 's nutcracker mask was - the " jaws " actually seemed to move whenever xxmaj baryshnikov xxunk his head back . \n\n xxmaj the dancing itself in the xxmaj</td>
      <td>xxmaj oz " ( that film 's makeup results though , worked xxunk , as this one 's does not ) . xxmaj and a comparison with xxmaj baryshnikov 's nutcracker in * his * production shows how wonderfully creative xxmaj baryshnikov 's nutcracker mask was - the " jaws " actually seemed to move whenever xxmaj baryshnikov xxunk his head back . \n\n xxmaj the dancing itself in the xxmaj macaulay</td>
      <td>the xxunk 's xxunk xxunk 's is ) is are ) and out by and well is is xxunk ) work . xxmaj the the few of the xxunk 's xxunk is the * xxmaj xxunk list that xxmaj xxmaj and xxunk 's xxmaj is is . the xxunk xxunk " scene made to be from he fuqua 's the head . to xxmaj xxmaj the xxunk is is this film xxunk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>their boat driver is killed ( hung ) and the boat disappears , so they find themselves trapped and basically at the xxunk of the " lady in xxmaj black . " \n\n xxmaj so what can you expect to find here ? xxmaj plenty of xxunk ! xxmaj one of the characters has their lips sewn shut and is then hung upside down in the fireplace and accidentally slow - xxunk</td>
      <td>boat driver is killed ( hung ) and the boat disappears , so they find themselves trapped and basically at the xxunk of the " lady in xxmaj black . " \n\n xxmaj so what can you expect to find here ? xxmaj plenty of xxunk ! xxmaj one of the characters has their lips sewn shut and is then hung upside down in the fireplace and accidentally slow - xxunk by</td>
      <td>xxunk xxunk ( xxmaj . he up . the two is . but the go the in in trapped xxunk the beginning of the ship xxunk and the red " " xxmaj xxmaj the , is you say from see out is xxmaj the of fun , xxmaj the of the most is a own xxunk together , xxunk xxunk xxunk up down . the end . the xxunk down at by</td>
    </tr>
    <tr>
      <th>3</th>
      <td>xxunk . i particularly enjoyed the ancient xxmaj xxunk class and the xxunk of ' xxunk ' . \n\n xxmaj it had a feeling of ' story of xxup o ' - that is , where people of means indulge in xxunk sexual adventure . xxmaj as she walks around the fantastic apartment in the buff , she is at ease - and why not , what is to xxunk a "</td>
      <td>. i particularly enjoyed the ancient xxmaj xxunk class and the xxunk of ' xxunk ' . \n\n xxmaj it had a feeling of ' story of xxup o ' - that is , where people of means indulge in xxunk sexual adventure . xxmaj as she walks around the fantastic apartment in the buff , she is at ease - and why not , what is to xxunk a " devil</td>
      <td>xxmaj xxmaj think enjoyed the xxunk xxmaj xxunk xxunk , the xxunk of the the ' . xxmaj xxmaj the 's a lot of xxunk xxunk ' xxmaj xxunk ' and a it , of the are the are themselves their their xxunk . xxmaj the a has in in xxunk xxunk , xxmaj xxmaj 's she is xxunk the , and xxunk is xxunk and is the do ? little xxunk</td>
    </tr>
    <tr>
      <th>4</th>
      <td>perfect is because they could have taken it even further , but they did n't . \n\n xxmaj the mix of both is mixed . i thought it was funny , but as with most all comedies , it was n't xxup that funny . i had my mom and little sister watch it with me and the jokes we made about it were funnier than the jokes scripted . xxmaj there</td>
      <td>is because they could have taken it even further , but they did n't . \n\n xxmaj the mix of both is mixed . i thought it was funny , but as with most all comedies , it was n't xxup that funny . i had my mom and little sister watch it with me and the jokes we made about it were funnier than the jokes scripted . xxmaj there were</td>
      <td>xxmaj the of are have been the for more . but it did n't have xxmaj xxmaj the plot of xxunk xxunk a together xxmaj think it was a , but it i the other the , it was a a ok bad . xxmaj was to expectations xxunk i xxunk , it . me . i rest were got were the were very . the xxunk . . xxmaj the were</td>
    </tr>
    <tr>
      <th>5</th>
      <td>there 's got to be a problem … xxbos xxmaj like xxmaj tarzan the xxmaj ape xxmaj man ( 1932 ) , only more so . xxmaj there 's more of everything , more animals , more varied xxmaj african tribes , and scenes in which the thought must be , if this was good with three or four lions , forty would be better . xxmaj tarzan xxunk with xxunk the</td>
      <td>'s got to be a problem … xxbos xxmaj like xxmaj tarzan the xxmaj ape xxmaj man ( 1932 ) , only more so . xxmaj there 's more of everything , more animals , more varied xxmaj african tribes , and scenes in which the thought must be , if this was good with three or four lions , forty would be better . xxmaj tarzan xxunk with xxunk the crocodile</td>
      <td>is no to be a lot with but xxmaj this many xxunk , xxmaj kid , hunter , xxunk ) , xxmaj two than - xxmaj the are no to a in it than , and of characters xxunk xxmaj , and a of which the characters of be xxunk but you is a . the xxunk four xxunk . then xxunk be xxunk than xxmaj the is a a , xxunk</td>
    </tr>
    <tr>
      <th>6</th>
      <td>the most intriguing , and in my opinion , he deserved a bit more screen - time . xxmaj amy xxmaj ryan also performs her job xxunk . \n\n xxup before xxup the xxup devil xxup knows xxup you 're xxup dead is not an exceptional movie , but it proves that xxmaj lumet is still near the top of his game at the ( apparent ) twilight of an illustrious career</td>
      <td>most intriguing , and in my opinion , he deserved a bit more screen - time . xxmaj amy xxmaj ryan also performs her job xxunk . \n\n xxup before xxup the xxup devil xxup knows xxup you 're xxup dead is not an exceptional movie , but it proves that xxmaj lumet is still near the top of his game at the ( apparent ) twilight of an illustrious career .</td>
      <td>xxmaj interesting part the the the opinion , the was the xxmaj of . time time . \n\n the xxmaj xxunk is has a best with , xxmaj xxmaj xxunk xxup dawn xxup xxunk xxup begins xxup the xxup xxup not xxup a a xxunk film , but it 's that you xxunk xxmaj not a the top of the career . the time xxunk ) xxunk zone the old xxunk .</td>
    </tr>
    <tr>
      <th>7</th>
      <td>looks xxmaj american but , on the other hand , xxunk they prefer xxmaj american series ( xxrep 3 ! ) . xxmaj maybe it 's the language , or the spirit , but i think this series is more xxmaj english than xxmaj american . xxmaj by the way , the actors are really good and funny . xxmaj the acting is not superficial at all … xxbos xxmaj this film</td>
      <td>xxmaj american but , on the other hand , xxunk they prefer xxmaj american series ( xxrep 3 ! ) . xxmaj maybe it 's the language , or the spirit , but i think this series is more xxmaj english than xxmaj american . xxmaj by the way , the actors are really good and funny . xxmaj the acting is not superficial at all … xxbos xxmaj this film is</td>
      <td>like xxunk xxmaj the in the other hand , the is are the xxunk xxunk . especially 3 0 ) . xxmaj the it 's a only that but the xxunk of but it do it is is a of american - xxmaj english . xxmaj the the end , the series are all good . the . xxmaj the xxmaj is good good , all . xxmaj xxmaj this movie is</td>
    </tr>
    <tr>
      <th>8</th>
      <td>jacket , xxmaj pulp xxmaj fiction , xxmaj true xxmaj romance , 12 xxmaj monkeys , xxmaj xxunk , etc . xxmaj there 's no irony in watching good movies . xxmaj the true decline of the western civilization . xxmaj calling this a cult film is an xxmaj insult to true xxmaj cult classics like xxmaj xxunk man , or even xxmaj xxunk . xxmaj i 've said enough here .</td>
      <td>, xxmaj pulp xxmaj fiction , xxmaj true xxmaj romance , 12 xxmaj monkeys , xxmaj xxunk , etc . xxmaj there 's no irony in watching good movies . xxmaj the true decline of the western civilization . xxmaj calling this a cult film is an xxmaj insult to true xxmaj cult classics like xxmaj xxunk man , or even xxmaj xxunk . xxmaj i 've said enough here . xxbos</td>
      <td>and and xxunk xxmaj fiction , and xxunk xxmaj story , xxmaj xxmaj days , xxmaj xxunk xxmaj xxmaj . xxmaj the are no xxunk , this this movies . xxmaj the story story of the genre genre is xxmaj the the film movie movie is a xxunk american xxmaj the story science - . xxmaj the xxmaj xxmaj xxmaj xxmaj xxmaj xxunk xxmaj xxmaj the 'm seen that to that xxmaj</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save_encoder</span><span class="p">(</span><span class="s1">&#39;enc1&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Use-it-to-train-a-classifier">Use it to train a classifier<a class="anchor-link" href="#Use-it-to-train-a-classifier">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For classification, we need to use two set of transforms: one to numericalize the texts and the other to encode the labels as categories. Note that we have to use the same vocabulary as the one used in fine-tuning the language model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lm_vocab</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">vocab</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">splits</span> <span class="o">=</span> <span class="n">ColSplitter</span><span class="p">()(</span><span class="n">df</span><span class="p">)</span>
<span class="n">x_tfms</span> <span class="o">=</span> <span class="p">[</span><span class="n">attrgetter</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">),</span> <span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">),</span> <span class="n">Numericalize</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">lm_vocab</span><span class="p">)]</span>
<span class="n">dsets</span> <span class="o">=</span> <span class="n">Datasets</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">splits</span><span class="o">=</span><span class="n">splits</span><span class="p">,</span> <span class="n">tfms</span><span class="o">=</span><span class="p">[</span><span class="n">x_tfms</span><span class="p">,</span> <span class="p">[</span><span class="n">attrgetter</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">),</span> <span class="n">Categorize</span><span class="p">()]],</span> <span class="n">dl_type</span><span class="o">=</span><span class="n">SortedDL</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We once again use a subclass of <a href="/data.core#TfmdDL"><code>TfmdDL</code></a> for the dataloaders, since we want to sort the texts (sortish for the training set) by order of lengths. We also use <code>pad_collate</code> to create batches form texts of different lengths.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dsets</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">before_batch</span><span class="o">=</span><span class="n">pad_input_chunk</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And there is a factory method, once again:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">TextDataLoaders</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">text_col</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">text_vocab</span><span class="o">=</span><span class="n">lm_vocab</span><span class="p">,</span> <span class="n">label_col</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">,</span> <span class="n">valid_col</span><span class="o">=</span><span class="s1">&#39;is_valid&#39;</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \n\n xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , xxunk bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the xxunk and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that</td>
      <td>positive</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we once again have a convenience function to create a classifier from this <a href="/data.core#DataLoaders"><code>DataLoaders</code></a> with the <a href="/text.models.awdlstm#AWD_LSTM"><code>AWD_LSTM</code></a> architecture.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">text_classifier_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">AWD_LSTM</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">accuracy</span><span class="p">],</span> <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span><span class="n">drop_mult</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">load_encoder</span><span class="p">(</span><span class="s1">&#39;enc1&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we can train with gradual unfreezing and differential learning rates.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.716138</td>
      <td>0.586119</td>
      <td>0.775000</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.575132</td>
      <td>0.463823</td>
      <td>0.770000</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.508140</td>
      <td>0.474733</td>
      <td>0.780000</td>
      <td>00:04</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.478295</td>
      <td>0.469056</td>
      <td>0.790000</td>
      <td>00:04</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">opt</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">create_opt</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span><span class="mf">1e-3</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.379919</td>
      <td>0.454718</td>
      <td>0.810000</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.392695</td>
      <td>0.480548</td>
      <td>0.780000</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.363343</td>
      <td>0.470170</td>
      <td>0.810000</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.319937</td>
      <td>0.478629</td>
      <td>0.805000</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.284388</td>
      <td>0.487241</td>
      <td>0.805000</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.256194</td>
      <td>0.475965</td>
      <td>0.810000</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.239991</td>
      <td>0.483625</td>
      <td>0.795000</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.229265</td>
      <td>0.487338</td>
      <td>0.810000</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">max_n</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>category</th>
      <th>category_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj i 'm sure things did n't exactly go the same way in the real life of xxmaj homer xxmaj hickam as they did in the film adaptation of his book , xxmaj rocket xxmaj boys , but the movie " october xxmaj sky " ( an xxunk of the book 's title ) is good enough to stand</td>
      <td>positive</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxmaj to review this movie , i without any doubt would have to quote that memorable scene in xxmaj tarantino 's " pulp xxmaj fiction " ( xxunk ) when xxmaj jules and xxmaj vincent are talking about xxmaj mia xxmaj wallace and what she does for a living . xxmaj jules tells xxmaj vincent that the " only</td>
      <td>negative</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xxbos xxmaj how viewers react to this new " adaption " of xxmaj shirley xxmaj jackson 's book , which was promoted as xxup not being a remake of the original 1963 movie ( true enough ) , will be based , i suspect , on the following : those who were big fans of either the book or original</td>
      <td>negative</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>3</th>
      <td>xxbos xxmaj the trouble with the book , " memoirs of a xxmaj geisha " is that it had xxmaj japanese xxunk but underneath the xxunk it was all an xxmaj american man 's way of thinking . xxmaj reading the book is like watching a magnificent ballet with great music , sets , and costumes yet performed by xxunk</td>
      <td>negative</td>
      <td>negative</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s2">&quot;This was a good movie&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;positive&#39;, tensor(1), tensor([8.0448e-05, 9.9992e-01]))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai2.interpret</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interp</span> <span class="o">=</span> <span class="n">Interpretation</span><span class="o">.</span><span class="n">from_learner</span><span class="p">(</span><span class="n">learn</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">interp</span><span class="o">.</span><span class="n">plot_top_losses</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>input</th>
      <th>target</th>
      <th>predicted</th>
      <th>probability</th>
      <th>loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj i 'm gon na xxunk the xxunk here a bit and say i enjoyed this . xxmaj however , the cartoon is really only going to appeal to those who have very xxunk xxunk . xxmaj it 's definitely something that most people will not get , as is the nature of xxunk . \n\n the animation is horrible , but yes , that 's the point . xxmaj the main character is foul mouthed , violent , and stupid . no redeeming qualities whatsoever . his wife xxunk and xxunk , apparently just barely capable of the most basic xxunk skills . most of these stories completely lack any kind of point . \n\n but again , that 's the point xxunk \n\n xxmaj if non xxunk , foul language , and complete and utter xxunk are your thing , you 're going to love this .</td>
      <td>positive</td>
      <td>negative</td>
      <td>0.9995182752609253</td>
      <td>7.638226509094238</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxmaj most italian horror lovers seem to hate this movie since because it has no connection to the first two xxmaj demons films . xxmaj and with the " demons xxrep 3 i " in the title , one would assume it would . xxmaj the problem is that this film was never intended to be part of the xxmaj demons series . xxmaj the distributors only a " demons xxrep 3 i " above its original title " the xxmaj ogre " to cash in on the other films popularity . xxmaj the new xxmaj american xxup dvd release of this picture has the title " demons xxrep 3 i : xxmaj the xxmaj ogre " on the box art but the film itself only says " the xxmaj ogre " . i do n't know if past releases had the title " demons xxrep 3 i "</td>
      <td>positive</td>
      <td>negative</td>
      <td>0.9945324659347534</td>
      <td>5.208930015563965</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xxbos xxmaj for anyone who may not know what a one - actor movie was like , this is the best example . xxmaj this plot is ridiculous , and really makes no sense . xxmaj it 's full of xxunk situations , hackneyed lines , melodrama , comedy … you name it ! \n\n xxmaj but xxmaj xxunk xxmaj xxunk can make anything convincing , and this movie is by no means an exception . xxmaj everyone turns in a decent performance - xxmaj xxunk xxmaj xxunk , xxmaj xxunk xxmaj xxunk , xxmaj xxunk , xxmaj om xxmaj xxunk , xxmaj xxunk xxmaj xxunk … xxmaj but it is the xxmaj xxunk who xxunk everyone with his xxunk presence . xxmaj without him , this movie would have been a non - xxunk … xxmaj the story is about xxunk / mistaken identities / misunderstandings / love /</td>
      <td>positive</td>
      <td>negative</td>
      <td>0.9913495779037476</td>
      <td>4.750149726867676</td>
    </tr>
    <tr>
      <th>3</th>
      <td>xxbos xxmaj this one is a little better than the first one . xxmaj it still relies on a lot of its humor which basically keeps saying that the old xxmaj bond movies were not realistic . xxmaj that wears thin after so many xxunk . xxmaj the girls were more interesting in this one . \n\n xxmaj there is a tremendous amount of total gross out humor . xxmaj hopefully one day real comedy will come back .</td>
      <td>negative</td>
      <td>positive</td>
      <td>0.9783519506454468</td>
      <td>3.832839250564575</td>
    </tr>
    <tr>
      <th>4</th>
      <td>xxbos xxmaj i 'm not sure under what circumstances director xxmaj visconti decided to film xxmaj james xxmaj cain 's novel " the xxmaj xxunk xxmaj always xxmaj rings xxmaj twice " ( i 'm not even sure if xxmaj xxunk acquired the book 's rights ) , but the resulting movie is definitely interesting . xxmaj it is not the best version of xxmaj cain 's story ( i like the 1981 version best ) , but thanks to xxmaj visconti 's excellent direction and the casting of xxmaj clara xxmaj xxunk and xxmaj xxunk xxmaj xxunk ( a very sensual couple ) , it is a must for noir fans . xxmaj visconti xxunk xxunk with noir xxunk to great effect . xxmaj the film is not perfect , though . xxmaj my main complaint is that the film is a little too long for its own good</td>
      <td>positive</td>
      <td>negative</td>
      <td>0.9690021276473999</td>
      <td>3.4738378524780273</td>
    </tr>
    <tr>
      <th>5</th>
      <td>xxbos xxmaj weaker entry in the xxmaj xxunk xxmaj drummond series , with xxmaj john xxmaj howard in the role . xxmaj usual funny xxunk and antics , but not much plot . xxmaj barrymore gets something to do as the inspector , xxunk xxunk to follow xxmaj drummond , xxmaj algy , and xxmaj xxunk on a wild xxunk chase ( mostly in circles ; perhaps the budget was tighter than usual ) to rescue poor xxmaj xxunk , who is being held captive by people who want to lure xxmaj drummond to his doom . xxmaj for those keeping score , in this one , xxmaj drummond is planning to ask xxmaj xxunk to marry him and xxmaj algy is worried about missing the baby 's xxunk . xxmaj it 's fun to see xxmaj algy and xxmaj xxunk dressed up as xxunk to blend in at xxmaj</td>
      <td>negative</td>
      <td>positive</td>
      <td>0.9453215003013611</td>
      <td>2.9062843322753906</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}
</div>
 

